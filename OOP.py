# -*- coding: utf-8 -*-
"""Model Deployment UTS OOP NO 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WbNQ5eF54lY-7RBkjNMDlLeo6R-dG4a7

# Libraries
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import RobustScaler, OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.model_selection import GridSearchCV
from warnings import filterwarnings
import pickle as pkl
filterwarnings('ignore')
seed = 42

class dataRead:
  def __init__(self, file):
      self.file = file
      self.df = None
  def readData(self):
    self.df = pd.read_csv(self.file)
    return self.df.head(5)

class EDA:
    def __init__(self, data :dataRead):
        self.data = data
        self.catCol = []
        self.numCol = []

    def Info(self):
        return self.data.info()

    def Drop(self, column):
        return self.data.drop(column, axis = 1, inplace = True)

    def CheckNull(self):
        return self.data.isnull().sum()

    def CheckDuplicate(self):
        return self.data[self.data.duplicated()].any()

    def DropDuplicate(self):
        return self.data.drop_duplicates()

    def CheckUnique(self, column):
        return print(self.data[column].unique())

    def toString(self, column):
        self.data[column] = self.data[column].astype(object)
        if column in self.numCol:
           self.numCol.remove(column)

    def toNum(self, column):
        self.data[column] = pd.to_numeric(self.data[column], errors = "coerce")

    def catCols(self):
        self.catCol = self.data.select_dtypes(include=['object']).columns
        return self.catCol

    def numCols(self):
        self.numCol = self.data.select_dtypes(include=['int64', 'float64']).columns
        return self.numCol

    def CheckOutlier(self, column):
        plt.figure(figsize=(6, 4))
        sns.boxplot(y=self.data[column])
        plt.title("Boxplot")
        plt.show()

    def fillnaNumMed(self, column):
        self.data[column] = self.data[column].fillna(self.data[column].median())

    def fillnaCat(self, column):
        self.data[column] = self.data[column].fillna(self.data[column].mode()[0])

    def CheckDistribution(self, column):
        data = self.data[column].value_counts()
        label = data.index

        colors = sns.color_palette('pastel', len(label))

        plt.figure(figsize = (8,6))
        plt.pie(data, labels = label, autopct = '%1.1f%%',
            explode = [0.02] * len(label),
            startangle = 90,
            colors = colors)
        plt.title(f'{column} Count')
        plt.show()

    def CheckCorr(self, column):
      corr = self.data[column].corr(method = 'pearson')
      sns.heatmap(corr, annot = True,
                cmap = 'coolwarm',
                fmt = '.2f',center = 0, vmin = -1,
                annot_kws = {'size': 10, 'weight':'bold', 'color':'white'})
      plt.title('Correlation of each Numerical Features')
      plt.show()

class preprocessing:
    def __init__(self, data: dataRead):
        self.data = data

        self.X = None
        self.y = None

        self.X_train = None
        self.y_train = None
        self.X_trainscale = None

        self.X_test = None
        self.y_test = None

        self.rs = None
        self.label_map = {'Not_Canceled': 0, 'Canceled': 1}
        self.ord_map = {'Complementary': 0, 'Offline': 1, 'Online': 2, 'Aviation': 3, 'Corporate': 4}


    def x_y_split(self, target):
        self.X = self.data.drop(target, axis = 1)
        self.y = self.data[target]

    def train_split(self):
      self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=seed)
      return self.X_train, self.X_test, self.y_train, self.y_test

    def RobustScale(self, columns):
        self.rs = RobustScaler()
        self.X_trainscale = self.X_train.copy()
        self.X_testscale = self.X_test.copy()
        self.X_trainscale[columns] = self.rs.fit_transform(self.X_train[columns])
        self.X_testscale[columns] = self.rs.transform(self.X_test[columns])

        pkl.dump(self.rs, open('scaler.pkl', 'wb'))
        return self.X_trainscale, self.X_testscale

    def OneHot(self, column):
        ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
        encoded = ohe.fit_transform(self.data[column])
        encoded_df = pd.DataFrame(encoded, columns=ohe.get_feature_names_out(column), index=self.data.index)
        self.data.drop(columns=column, inplace=True)
        self.data = pd.concat([self.data, encoded_df], axis=1)
        pkl.dump(ohe, open('onehot.pkl', 'wb'))
        return self.data

    def ordinal(self, column):
      self.data[column] = self.data[column].map(self.ord_map)
      pkl.dump(self.ord_map, open('ordinal_map.pkl', 'wb'))
      return self.data

    def label(self, column):
      self.data[column] = self.data[column].map(self.label_map)
      pkl.dump(self.label_map, open('label_map.pkl', 'wb'))
      return self.data

    def toInt(self, column):
        self.data[column] = self.data[column].astype(int)

class Model:
    def __init__(self):
        self.model = None
        self.best_model = None
        self.best_params = None

    def XGB(self):
        self.model = XGBClassifier(random_state = seed)

    def train(self, X_train, y_train):
        self.model.fit(X_train, y_train.ravel())
        print("Model trained successfully!")

    def predict(self, X_test):
        return self.model.predict(X_test)

    def tuning(self, X_train, y_train, cv=5, scoring='accuracy'):
        xg_params = xg_params = {
                    'n_estimators': [100, 150, 200],
                    'learning_rate': [0.01, 0.05, 0.1],
                    'max_depth': [1, 2, 3],
                    }
        xg_grid = GridSearchCV(self.model,
                            xg_params, cv=cv,
                            scoring=scoring)
        xg_grid.fit(X_train, y_train)

        self.best_model = xg_grid.best_estimator_
        self.best_params = xg_grid.best_params_

        return self.best_model, self.best_params

    def evaluateTrain(self, X_train, y_train):
        y_pred_train = self.model.predict(X_train)
        print("Classification Report Train-set:\n", accuracy_score(y_train, y_pred_train))
        print(classification_report(y_train, y_pred_train))

    def evaluateTest(self, X_test, y_test):
        y_pred_test= self.model.predict(X_test)
        print("Classification Report Test-set:\n", accuracy_score(y_test, y_pred_test))
        print(classification_report(y_test, y_pred_test))

"""# EDA"""

data = dataRead('Dataset_B_hotel.csv')
data.readData()

analysis = EDA(data.df)
analysis.Info()

"""Dari data diatas kita dapat menyimpulkan data yang akan kita pakai/kita drop.
Saya memutuskan untuk drop booking ID karena booking ID tidak ada pengaruh dan untuk variabel waktu kedatangan juga tidak akan berpengaruh pada kemungkinan booking tersebut akan di cancel/not cancelled.
dari data description juga kita mengetahui bahwa adalah required_car_parking_space sebuah data binary yang bisa digantikan ke object terlebih dahulu untuk menemukan categorical column yang cocok
"""

analysis.Drop('Booking_ID')
analysis.Drop('arrival_year')
analysis.Drop('arrival_month')
analysis.Drop('arrival_date')

analysis.toString('required_car_parking_space')

analysis.catCols()
analysis.numCols()

for i in analysis.catCols():
  analysis.CheckUnique(i)

"""Dari hasil unique object diatas kita dapat menyimpulkan bahwa semua kolom categorical tidak memiliki hirarki kecuali market_segment sehingga kita dapat menggunakan ordinal encoding dan sisanya dapat menggunakan one hot encoding dan untuk booking_status kita dapat menggunakan label encoding"""

analysis.CheckDuplicate()

analysis.DropDuplicate()

analysis.CheckNull()

for i in analysis.numCols():
  analysis.CheckOutlier(i)

"""Dari Graph diatas kita dapat melihat semua numerical columns memiliki outlier sehingga untuk nan values dapat diisi dengan median khususnya untuk avg price per room. Untuk kolom seperti required_car_parking_space bersifat binary sehingga bisa dibilang object maka itu saya aku melakukan imputasi menggunakan mode nilainya yaitu 0 karena 1 adalah outlier"""

analysis.fillnaNumMed('avg_price_per_room')
analysis.fillnaCat('required_car_parking_space')
analysis.fillnaCat('type_of_meal_plan')
analysis.toString('required_car_parking_space')

analysis.CheckDistribution('booking_status')

"""Dari graph diatas kita dapat melihat bahwa distribusi target variabel tidak seimbang sehingga menyebabkan model memiliki bias, maka itu untuk evaluation metric F1-score akan memiliki kepercayaan yang lebih tinggi dibanding dengan accuracy"""

analysis.CheckCorr(analysis.numCols())

"""# Feature Engineering

## Encoding
"""

preprocess = preprocessing(analysis.data)
preprocess.ordinal('market_segment_type')
preprocess.label('booking_status')
preprocess.OneHot(['type_of_meal_plan', 'room_type_reserved'])
preprocess.toInt('required_car_parking_space')
preprocess.x_y_split('booking_status')

X_train, X_test, y_train, y_test = preprocess.train_split()

X_train, X_test = preprocess.RobustScale(analysis.numCol)

learn = Model()

learn.XGB()
learn.train(X_train, y_train)
learn.predict(X_test)
learn.evaluateTrain(X_train, y_train)
learn.evaluateTest(X_test, y_test)

tuned = Model()
tuned.XGB()
best_model, best_params = tuned.tuning(X_train, y_train)
tuned.model = best_model
tuned.predict(X_test)
tuned.evaluateTrain(X_train, y_train)
tuned.evaluateTest(X_test, y_test)

import pickle as pkl

filename = 'TunedXG.pkl'
pkl.dump(best_model, open(filename, 'wb'))

